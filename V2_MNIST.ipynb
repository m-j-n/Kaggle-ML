{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open training set, copy labels, drop labels from set\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "train_labels = train['label'] \n",
    "train = train.drop('label', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 784)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create numpy array from pandas dataframe for future manipulation\n",
    "\n",
    "train_array = train.values\n",
    "labels_array = labels.values\n",
    "\n",
    "X, Y = train_array, labels_array  #create tuple couple to keep organized\n",
    "\n",
    "X.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x25c085acfd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#plot a number to make sure they are in right format\n",
    "\n",
    "random_digit = X[199]\n",
    "random_digit_image = random_digit.reshape(28, 28)           #reshape to 28 by 28 array which is pixels of orig image\n",
    "plt.imshow(random_digit_image)\n",
    "plt.show()\n",
    "Y[199]               #value should match image if tuple couple is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary Classifier - simplify problem and start by identifying only '2 or 'not 2\n",
    "\n",
    "# Seperate Training and Test Set\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = X[:32000], X[32000:], Y[:32000], Y[32000:]\n",
    "\n",
    "Y_train_2= (Y_train == 2)    #True for 2 false for all other\n",
    "Y_test_2= (Y_test == 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ True], dtype=bool)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Classifier Selection and Training\n",
    "# SGD = Stochastic Gradient Descent\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier \n",
    "\n",
    "sgd_clf = SGDClassifier(random_state=42)\n",
    "sgd_clf.fit(X_train, Y_train_2)\n",
    "\n",
    "sgd_clf.predict([random_digit])     #test on digit from above, it guesses true! Now time to evaluate model performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.9703787 ,  0.96831052,  0.96681043])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first evaluation using cross-validation\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cross_val_score(sgd_clf, X_train, Y_train_2, cv=3, scoring='accuracy')  \n",
    "\n",
    "#although accuracy > 96%, a simple not 5 classifier would be around 90% so need a better way to evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[28288,   498],\n",
       "       [  510,  2704]], dtype=int64)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# time to make a confusion matrix\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "Y_train_pred = cross_val_predict(sgd_clf, X_train, Y_train_2, cv=3)  #creates 'clean' predictions from the data\n",
    "\n",
    "confusion_matrix(Y_train_2, Y_train_pred)\n",
    "\n",
    "# rows of confusion matrix = actual class, columns = predicted class. top right = false positives, bottom left= false negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.84447220487195507, 0.8413192283758556)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Precision (accuracy of positive pred) and Recall (ratio of correct positive instances) Calculation\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "precision_score(Y_train_2, Y_train_pred), recall_score(Y_train_2, Y_train_pred) #gives around 84% for both\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84289276807980063"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# F1 score = harmonic mean (combines recall and precision into single metric)\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_score(Y_train_2, Y_train_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2], dtype=int64)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ok binary classifier isn't great but time to scale to a multiclass classifier \n",
    "\n",
    "sgd_clf.fit(X_train, Y_train) #trains target class from 0-9. Trains 10 binary classifiers and picks strongest output\n",
    "sgd_clf.predict([random_digit]) # predicts what this digit is, it gets it right!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.86243089,  0.83238024,  0.8399925 ])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's check out the cross_val score\n",
    "cross_val_score(sgd_clf, X_train, Y_train, cv=3, scoring='accuracy')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2], dtype=int64)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# time to check out a random forest classifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest_clf = RandomForestClassifier(random_state=42)\n",
    "forest_clf.fit(X_train, Y_train)\n",
    "forest_clf.predict([random_digit])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.92971605,  0.92818974,  0.9289064 ])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(forest_clf, X_train, Y_train, cv=3, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
